# This file was generated by Rcpp::compileAttributes
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Estimate Transfer Entropy.
#'
#' \code{ComputeTE} Estimate the Transfer Entropy (TE) from one random process to another. 
#'
#' A function to calculate Transfer Entropy from random process \code{Y} to random process \code{X}. The definition of TE assumes \code{X} is an Markov process. The  \code{embedding} dimension should be chosen to match the delay of the Markov process. The TE measures the additional amount of information \code{Y} contains about \code{X} over the information contained in the Markov embedding.
#' Two \code{methods} for estimating TE are provided. The first is based on the mutual information distance \code{MI(X_i+1 | X^{(e) },Y_i) - MI(X_i+1 | X^{(e)} )}, where \code{e} is the embedding dimension. This approach follows directly from the definition of the TE. Mutual information is estimated using the \code{k}-nearest neighbor approach suggested by Krasvok.
#' The second method is based on the generalized correlation sum. 
#'
#' Things can go wrong in several ways. First, the random processes must meet the assumption of the TE. That is, \code{X} must represent some form of Markov process whose probability distribution may also be influenced by \code{Y}. A more subtle error can occur when multiple points in \code{X^(k)} (or some of its subspaces) have identical coordinates. This can lead to several points which have identical distance to a query point, which violates the assumptions of the Kraskov estimator, causing it to throw an error. The solution in this case is to add some small noise to the measurements \code{X} prior to computing TE.
#'
#' @param X Numeric vector, Transfer Entropy is calculated to random process X 
#' @param Y Numeric vector, Transfer Entropy is calculated from random process Y
#' @param embedding Numeric, The embedding dimension. Must be positive integer
#' @param k Numeric, The k'th neighbor. Must be positive integer. Kraskov suggests a value in (1,3).
#' @param method String, The method to be used to estimate TE from ("MI_dif","Correlation")
#' @param epsDistace Numeric, The distance used for measuring TE in Correlation method, by default it is the average distance calculated in XKY
#' @return Numeric, The estimated transfer entropy
#' 
#' @family TODO arbitrary
#' @seealso TODO arbitrary
#' @aliases te transferentropy transfer-entropy
#' 
#' @examples
#' ## Intitialize two vectors of length 10001
#' X <- rep(0,10000+1) 
#' Y <- rep(0,10000+1)
#' ## Create two linked random processes. Y is independent of X,
#' ## while X is determined in part by the previous values of Y.
#' for(i in 1:10000){
#'   Y[i+1] <- 0.5*Y[i] + rnorm(1)
#'   X[i+1] <- 0.6*X[i] + 0.5*Y[i] + rnorm(1)
#' }
#' ## Compute the TE from X to Y 
#' ## and from Y to X
#' ComputeTE(X,Y,3,1,"MI_diff")  ## should be zero
#' ComputeTE(Y,X,3,1,"MI_diff")  ## should be ~0.35
#' ComputeTE(X,Y,1,1,"Correlation")
#' ComputeTE(Y,X,1,1,"Correlation")
#' ComputeTE(X,Y,3,1,"Correlation",0.5)
#' 

ComputeTE <- function(X, Y, embedding, k, method="MI_diff", epsDist=-1) {
  methods = c("correlation","mi_diff")
  method = charmatch(tolower(method),methods)
  if (is.na(method) )
    stop("Method not specified correctly. Please choose one of the following. (\"MI_diff\", \"Correlation\")")
  ## Sanity checks:
  if( embedding%%1 != 0 || embedding <= 0 )
    stop("Embedding should be an integer greater than zero")
  if( embedding > sqrt(length(X)) )
    warning("Embedding is big may not be sensible")
  if( k%%1 != 0 || k <= 0 )
    stop("k (neighbor) should be an integer greater than zero")
  if( k > 10 )
    warning("k is big may not be sensible")
  if( length(X) != length(Y))
    stop("X and Y should have the same length")
  
  .Call('Rcpp_ComputeTE', X, Y, embedding, k, methods[method], epsDist, PACKAGE = 'ComputeTE')
}


## WARNING if you want to extend the codebase !!
## The algorithms used here assume nearest neighbors are determined using the max norm. We implement the nearest neigbhor search using the ANN (Approximate Nearest Neighbor) library. ANN is set to use the max norm by adjusting some variables in the library's header files. Keep this in mind if you choose to extend this library


